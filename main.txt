#Read the bank.csv file into R
bank <- read.csv('bank.csv', sep=';', stringsAsFactors TRUE)
# Summary statistics on uncleaned dataset
summary(bank)

#Remove the column poutcome
bank <- subset(bank, select = -poutcome)

# Replacing the 'unknown' values with 'NA'
bank [bank == 'unknown'] <- NA

#removing the rows with 'unknown' values 
bank<-na.omit(bank)

﻿

# Summary statistics of cleaned data
summary(bank)

﻿
# set seed allows the sample to be reproduced again if needed 
set.seed(42)
# Selecting 80% of the data to be training data the other 20% will be test data 
nrow(bank), size floor(.8 nrow(bank)), replace
sample <- sample. int(n = nrow(bank), size floor(.8 nrow(bank)), replace = F)
train bank[sample, ] 
test bank[sample, ] 

﻿

install.packages("Rweka") 
1ibrary(Rweka)
install.packages("partykit")
library(partykit)
#CTree Classifier: Training the classifier
tree_clf <- ctree(y ~ ., data = train)
#Testing and Prediction
pred <- predict(tree_cl, test)
actual <- test$y	
#Computing True Positives
tp <- sum(actual == "yes" & pred == "yes")
#Computing False Positives
fp <- sum(actual =="no" & pred == "yes")
#Computing True Negatives
tn<- sum(actual == "no" & pred == "no")
#Computing False Negatives
fn <- sum(actual == "yes" & pred "no")
#Creation of Confusion Matrix
cml <- data.frame("Confusion Matrix" = c("Actual Yes", "Actual No"), 
                  "Predicted Yes" = c(tp, fp), 
                  "Predicted No" = c(fn, tn))
cml

﻿

# Computing Performance Measures 
accuracy (tp+tn)/nrow(test)
error_rate <- 1 - accuracy 
precision<- tp/(tp+fp)
recall tp/(tp+fn)
f1_score <- 2*precision recall/(precision+recall)

﻿

#348 Classifier: Training the classifier 
j48_clf <- j48(y ~. ,data =train) 
#Testing and Prediction
pred <- predict(j48_clf, test) 
actual <- test$y
#Computing true positives
tp2 <-sum(actual == "yes" & pred == "yes") 
#Computing False Positives
fpz <- sum(actual == 'no' & pred =='yes')
#Computing True Negatives
tnz <- sum(actual == 'no' & pred == 'no") 
#Computing False Negatives
fnz <- sum(actual == "yes" & pred =="no")
#Creation of Confusion Matrix
cm2 <- data.frame("Confusion Matrix" = 	c("Actual Yes", "Actual No"), "Predicted Yes" = c(tp2, fp), "Predicted No" = c(fn2, tn2))
cm2

﻿

#Linear Classifier: Training the classifier 
linear_clf <- glm(y ~. , data = train, famil=-"binomial") 
#Testing and Prediction
pred_vol <- predict(linear_clf, test)
#Use threshold given in assignment instructions 
threshold <- 1.5
pred<- ifelse(pred_vol > threshold, "yes", "no") 
actual<- test$y
#Computing True Positives
tp <- sum(actual == "yes" & pred == "yes") 
#Computing False Positives
fp <- sum(actual == "no" & pred == "yes") 
#Computing True Negatives
tn <- sum(actual == "no" & pred == "no")
#Computing False Negatives
fn <- sum(actual == "yes" & pred == "no")
#Creation of Confusion Matrix
cm3 data.frame("Confusion Matrix" = c("Actual Yes", "Actual No"), "Predicted Yes" = c(tp, fp), "Predicted No" = c(fn, tn))
cm3

﻿

#knn Classifier: Training the classifier 
ctrl <- trainControl (method-"repeatedcv", repeats = 1) 
knn_clf <- train (y ~ ., data = train, method = "knn", trControl = ctrl, tuneLength=3)
#Prediction on the Test Data
pred <- predict(knn_clf, test) 
actual <- test$y
#Computing True Positives
tp <- sum(actual == "yes" & pred == "yes") 
#Computing False Positives
fp <- sum(actual == "no" & pred =="yes") 
#Computing True Negatives
tn <-sum(actual == "no" & pred =="no")
#Computing False Negatives
fn <- sum(actual == "yes" & pred == "no")
#Creation of Confusion Matrix
cm4<- data.frame("Confusion Matrix" = c("Actual Yes", "Actual No"), "Predicted Yes" = c(tp, fp), "Predicted No" = c(fn, tn))
cm4


#Accuracy Bar Chart
classifiers <- c("CTree", "J48", "Linear", "KNN")
accy <- c(0.8737, 0.8712, 0.8585, 0.8580)
# Bar Chart
barplot(accy*100,
main = "Accuracy of Each Classifier", 
xlab = "Accuracy as a Percentage", 
ylab = "Classifier", 
names.arg = classifiers, 
col = "darkblue",	
horiz = TRUE)

#Error Rate Bar Chart
error <- 1 -accy

#Bar Plot
barplot(error*100,
main = "Error rates of each Classifier",
xlab = "Error rate as a percentage", 
ylab = "Classifier",
names.arg = classifiers,
col = "darkblue",
horiz = TRUE)

#5recision Bar Chart
precsn<- c(0.5826, 0.5796, 0.6423, 0.5381)

# Bar Plot
barplot(precsn,
main = "Precision of each Classifier",
xlab = "Precision",
ylab = "Classifier",
names.arg = classifiers,
col = "darkblue",
horiz = TRUE)

#Recall Bar Chart
recll<- c(0.5000, 0.4560, 0.0868, 0.2484)
#Bar Plot
barplot(recll,
main = "Recall of each Classifier", 
xlab = "Recall",
ylab = "Classifier", 
names.arg = classifiers, 
col = "darkblue",
horiz= TRUE)

# F1 Score Bar Chart
flscore <- c(0.5381, 0.5104, 0.1529, 0.3399) 
# Bar Plot 
barplot(flscore,
main = "F1-Score of each Classifier",
xlab ="F1-Score",
ylab = "Classifier",
names.arg = classifiers,
col = "darkblue",
horiz= TRUE)